### TODO:
- World is producing more and more data
- Business are storing more and more data
- Big Data Lakes with potential valuable information
- Requires Processing of Data
- Requires a lot of computational power, systems on single node are no longer enough to keep up with a stream of data
- Stream Processor frameworks like Spark and Flink
- Vastly different Runtime depending on Scheduling (Source?)
- Implementing/Testing new Scheduling Algorithms always require the Setup of an Cluster
- Unused Resources in a Production cluster due to inefficient Scheduling

### Open:
- How much detail is required here?